{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Merge transactions with products to get product category and price\n",
    "transactions = pd.merge(transactions, products, on='ProductID')\n",
    "\n",
    "# Feature Engineering: Create customer features\n",
    "# 1. Total spending per customer\n",
    "total_spending = transactions.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
    "total_spending.columns = ['CustomerID', 'TotalSpending']\n",
    "\n",
    "# 2. Average transaction value per customer\n",
    "avg_transaction_value = transactions.groupby('CustomerID')['TotalValue'].mean().reset_index()\n",
    "avg_transaction_value.columns = ['CustomerID', 'AvgTransactionValue']\n",
    "\n",
    "# 3. Favorite product category (most purchased category)\n",
    "favorite_category = transactions.groupby(['CustomerID', 'Category']).size().reset_index(name='Count')\n",
    "favorite_category = favorite_category.loc[favorite_category.groupby('CustomerID')['Count'].idxmax()]\n",
    "favorite_category = favorite_category[['CustomerID', 'Category']]\n",
    "favorite_category.columns = ['CustomerID', 'FavoriteCategory']\n",
    "\n",
    "# 4. Number of transactions per customer\n",
    "num_transactions = transactions.groupby('CustomerID').size().reset_index(name='NumTransactions')\n",
    "\n",
    "# 5. Total quantity purchased per customer\n",
    "total_quantity = transactions.groupby('CustomerID')['Quantity'].sum().reset_index()\n",
    "total_quantity.columns = ['CustomerID', 'TotalQuantity']\n",
    "\n",
    "# Merge all features into a single customer feature dataframe\n",
    "customer_features = pd.merge(customers, total_spending, on='CustomerID', how='left')\n",
    "customer_features = pd.merge(customer_features, avg_transaction_value, on='CustomerID', how='left')\n",
    "customer_features = pd.merge(customer_features, favorite_category, on='CustomerID', how='left')\n",
    "customer_features = pd.merge(customer_features, num_transactions, on='CustomerID', how='left')\n",
    "customer_features = pd.merge(customer_features, total_quantity, on='CustomerID', how='left')\n",
    "\n",
    "# Handle missing values (if any)\n",
    "customer_features.fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical features (FavoriteCategory and Region)\n",
    "customer_features = pd.get_dummies(customer_features, columns=['FavoriteCategory', 'Region'], drop_first=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['TotalSpending', 'AvgTransactionValue', 'NumTransactions', 'TotalQuantity']\n",
    "customer_features[numerical_features] = scaler.fit_transform(customer_features[numerical_features])\n",
    "\n",
    "# Drop non-relevant columns for similarity calculation\n",
    "customer_features.set_index('CustomerID', inplace=True)\n",
    "customer_features.drop(columns=['CustomerName', 'SignupDate'], inplace=True)\n",
    "\n",
    "# Calculate cosine similarity between customers\n",
    "similarity_matrix = cosine_similarity(customer_features)\n",
    "\n",
    "# Convert similarity matrix to a dataframe\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features.index, columns=customer_features.index)\n",
    "\n",
    "# Function to get top 3 similar customers\n",
    "def get_top_similar_customers(customer_id, similarity_df, top_n=3):\n",
    "    # Exclude the customer itself (similarity score = 1)\n",
    "    similar_customers = similarity_df[customer_id].drop(customer_id).sort_values(ascending=False).head(top_n)\n",
    "    return similar_customers\n",
    "\n",
    "# Generate recommendations for the first 20 customers (C0001 - C0020)\n",
    "lookalike_map = {}\n",
    "for customer_id in customer_features.index[:20]:\n",
    "    similar_customers = get_top_similar_customers(customer_id, similarity_df)\n",
    "    # Convert numpy.float64 to native Python float for better CSV compatibility\n",
    "    lookalike_map[customer_id] = [[similar_customer, float(score)] for similar_customer, score in zip(similar_customers.index, similar_customers.values)]\n",
    "\n",
    "# Convert the map to a dataframe\n",
    "lookalike_df = pd.DataFrame(lookalike_map.items(), columns=['CustomerID', 'Lookalikes'])\n",
    "\n",
    "# Save the lookalike recommendations to a CSV file\n",
    "lookalike_df.to_csv('Ankur_Bhadauria_Lookalike.csv', index=False)\n",
    "\n",
    "# Print the lookalike recommendations\n",
    "print(lookalike_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
